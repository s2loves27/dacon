{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline.ipynb<br>\n",
    ".. └ data<br>\n",
    ".... ├ train.json<br>\n",
    ".... ├ test.json<br>\n",
    ".... └ sample_submission.csv<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./data\"\n",
    "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
    "TEST_SOURCE = os.path.join(DIR, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SOURCE) as f:\n",
    "    TRAIN_DATA = json.loads(f.read())\n",
    "    \n",
    "with open(TEST_SOURCE) as f:\n",
    "    TEST_DATA = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
    "uid = 1000\n",
    "for data in TRAIN_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        train.loc[uid, 'uid'] = uid\n",
    "        train.loc[uid, 'title'] = data['title']\n",
    "        train.loc[uid, 'region'] = data['region']\n",
    "        train.loc[uid, 'context'] = context[:-1]\n",
    "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
    "        uid += 1\n",
    "\n",
    "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
    "uid = 2000\n",
    "for data in TEST_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        test.loc[uid, 'uid'] = uid\n",
    "        test.loc[uid, 'title'] = data['title']\n",
    "        test.loc[uid, 'region'] = data['region']\n",
    "        test.loc[uid, 'context'] = context[:-1]\n",
    "        uid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
    "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>summary</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
       "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
       "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
       "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
       "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
       "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                 title region  \\\n",
       "1000  1000         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1001  1001         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1002  1002         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1003  1003         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1004  1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록     완주   \n",
       "\n",
       "                                                context  \\\n",
       "1000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...   \n",
       "1001  의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...   \n",
       "1002  다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...   \n",
       "1003  다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...   \n",
       "1004  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...   \n",
       "\n",
       "                                                summary  \\\n",
       "1000                     제207회 완주군의회 임시회 제1차 본회의 개의 선포.   \n",
       "1001   제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.   \n",
       "1002    제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.   \n",
       "1003  8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...   \n",
       "1004                 제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.   \n",
       "\n",
       "                                                  total  \n",
       "1000  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...  \n",
       "1001  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....  \n",
       "1002  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...  \n",
       "1003  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...  \n",
       "1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2994, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2001</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2002</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2003</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2004</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                          title region  \\\n",
       "2000  2000  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2001  2001  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2002  2002  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2003  2003  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2004  2004  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "\n",
       "                                                context  \\\n",
       "2000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...   \n",
       "2001  의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...   \n",
       "2002  의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...   \n",
       "2003  의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...   \n",
       "2004  의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...   \n",
       "\n",
       "                                                  total  \n",
       "2000  제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...  \n",
       "2001  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...  \n",
       "2002  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...  \n",
       "2003  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...  \n",
       "2004  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_len = 500\n",
    "decoder_len = 50\n",
    "max_vocab_size = 20000\n",
    "batch_size = 32\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.iloc[:-200]\n",
    "df_val = train.iloc[-200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mecab_Tokenizer():\n",
    "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
    "        self.text_tokenizer = Mecab()\n",
    "        self.mode = mode\n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        self.max_length = max_length\n",
    "        self.word_count = {}\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        # 띄어쓰기를 찾기 위한 태그 목록\n",
    "        self.font_blank_tag = [\n",
    "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
    "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
    "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
    "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
    "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
    "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
    "        ]\n",
    "        self.back_blank_tag = [\n",
    "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
    "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
    "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
    "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
    "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
    "        ]\n",
    "        \n",
    "    def morpheme(self, sentence_list):\n",
    "        new_sentence = []\n",
    "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
    "            temp = []\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('sos_')\n",
    "            for t in self.text_tokenizer.pos(sentence):\n",
    "                temp.append('_'.join(t))\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('eos_')\n",
    "            new_sentence.append(' '.join(temp))\n",
    "            \n",
    "        return new_sentence\n",
    "    \n",
    "    def fit(self, sentence_list):\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    self.word_count[word] += 1\n",
    "                except:\n",
    "                    self.word_count[word] = 1\n",
    "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
    "        \n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        if self.max_vocab_size == -1:\n",
    "            for i, word in enumerate(list(self.word_count.keys())):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        else:\n",
    "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        \n",
    "    def sort_target(self, x):\n",
    "        return x[1]\n",
    "            \n",
    "    def txt2token(self, sentence_list):\n",
    "        tokens = []\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            token = [0]*self.max_length\n",
    "            for i, w in enumerate(sentence.split(' ')):\n",
    "                if i == self.max_length:\n",
    "                    break\n",
    "                try:\n",
    "                    token[i] = self.txt2idx[w]\n",
    "                except:\n",
    "                    token[i] = self.txt2idx['unk_']\n",
    "            tokens.append(token)\n",
    "        return np.array(tokens)\n",
    "    \n",
    "    def convert(self, token):\n",
    "        sentence = []\n",
    "        for j, i in enumerate(token):\n",
    "            if self.mode == 'enc':\n",
    "                if i != self.txt2idx['pad_']:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "            elif self.mode == 'dec':\n",
    "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
    "                    break\n",
    "                elif i != 0:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
    "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
    "                        try:\n",
    "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
    "                                sentence.append(' ')\n",
    "                        except:\n",
    "                            pass\n",
    "        sentence = \"\".join(sentence)\n",
    "        if self.mode == 'enc':\n",
    "            sentence = sentence[:-1]\n",
    "        elif self.mode == 'dec':\n",
    "            sentence = sentence[3:-1]\n",
    "            \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
    "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2794it [00:06, 419.01it/s]\n",
      "200it [00:00, 495.96it/s]\n",
      "506it [00:01, 401.71it/s]\n",
      "2794it [00:00, 7420.44it/s]\n",
      "200it [00:00, 9636.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src = src_tokenizer.morpheme(df_train.total)\n",
    "val_src = src_tokenizer.morpheme(df_val.total)\n",
    "test_src = src_tokenizer.morpheme(test.total)\n",
    "\n",
    "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
    "val_tar = tar_tokenizer.morpheme(df_val.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_src_max_len : 6476\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tar_max_len : 342\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_src_len = []\n",
    "for m in train_src:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_src_len.append(m_len)\n",
    "print('train_src_max_len :', max(train_src_len))\n",
    "plt.hist(train_src_len, bins=30)\n",
    "plt.show()\n",
    "\n",
    "train_tar_len = []\n",
    "for m in train_tar:\n",
    "    m_len = len(m.split(' '))\n",
    "    train_tar_len.append(m_len)\n",
    "print('train_tar_max_len :', max(train_tar_len))\n",
    "plt.hist(train_tar_len, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 7882.40it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 113657.51it/s]\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer.fit(train_src)\n",
    "tar_tokenizer.fit(train_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 11088.66it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 13016.90it/s]\n",
      "100%|██████████| 506/506 [00:00<00:00, 11338.50it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 124711.45it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 112947.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
    "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
    "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
    "\n",
    "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
    "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(src_tokenizer.txt2idx)\n",
    "target_vocab_size = len(tar_tokenizer.txt2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 4877)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제207회 완주군의회 임시회 제1차 본회의 개의 선포.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.summary.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3,    8, 1131,   19,   42,   21,   24,    8,   35,   25,   49,\n",
       "           5,   44,    5,   52,    2,    4,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]),\n",
       " ' 제 207 회 완주군 의회 임시회 제 1 차 본회의개의선포.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.src_tokens = src_tokens\n",
    "        if self.mode == 'train':\n",
    "            self.tar_tokens = tar_tokens\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        src_token = self.src_tokens[i]\n",
    "        if self.mode == 'train':\n",
    "            tar_token = self.tar_tokens[i]\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
    "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
    "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
    "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 Transformer\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/transformer 를 pytorch코드로 수정하여 작성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Dc7o26Txp_wh"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "K8l-XKICp_wi"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
    "    return seq  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.ones(size, size).triu(diagonal=1)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MrkZ_SWsp_wi"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = k.size()[-1]\n",
    "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print('Attention weights are:')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
      "Output is:\n",
      "tensor([[1.0000e+01, 9.2766e-25]])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = torch.tensor([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
    "\n",
    "temp_v = torch.tensor([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
      "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
      "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+02, 5.5000e+00],\n",
      "        [1.0000e+01, 9.2766e-25],\n",
      "        [5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[0, 0, 10],\n",
    "                      [0, 10, 0],\n",
    "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, v, k, q, mask):\n",
    "        batch_size = q.size()[0]\n",
    "        \n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
    "                \n",
    "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(FFN, self).__init__()\n",
    "        self.layer1 = nn.Linear(d_model, dff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 500, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048, encoder_len)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    torch.rand(64, encoder_len, 512), None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        self.dropout3 = nn.Dropout(rate)\n",
    "        \n",
    "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048, decoder_len)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    torch.rand(64, decoder_len, 512), sample_encoder_layer_output,\n",
    "    None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, x, mask, enc_output=None):\n",
    "        if enc_output == None:\n",
    "            seq_len = x.size()[1]\n",
    "            attention_weights = {}\n",
    "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "            x += self.pos_encoding[:, :seq_len, :]\n",
    "            x = self.dropout(x)\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.dec_layers[i](x, mask)\n",
    "        else:\n",
    "            x = enc_output\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 500, 512])\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=input_vocab_size,\n",
    "                         maximum_position_encoding=encoder_len,\n",
    "                         device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, mask=None, enc_output=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        \n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = x.size()[1]\n",
    "        attention_weights = {}\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 50, 512]), torch.Size([64, 8, 50, 500]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=target_vocab_size,\n",
    "                         maximum_position_encoding=decoder_len,\n",
    "                         device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, device, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, device, rate)\n",
    "\n",
    "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inp, tar, enc_output = inputs\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights, enc_output\n",
    "\n",
    "    def create_masks(self, inp, tar):\n",
    "        # Encoder padding mask\n",
    "        enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 2nd attention block in the decoder.\n",
    "        # This padding mask is used to mask the encoder outputs.\n",
    "        dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 1st attention block in the decoder.\n",
    "        # It is used to pad and mask future tokens in the input received by\n",
    "        # the decoder.\n",
    "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
    "        dec_target_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
    "\n",
    "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 4877])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size,\n",
    "    pe_input=encoder_len, pe_target=decoder_len, device='cpu')\n",
    "\n",
    "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
    "temp_target = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
    "\n",
    "fn_out, _, _ = sample_transformer([temp_input, temp_target, None])\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    pe_input=encoder_len,\n",
    "    pe_target=decoder_len-1,\n",
    "    device=device,\n",
    "    rate=dropout_rate\n",
    ")\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 옵티마이저, 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 및 평가함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    loss_ = criterion(pred.permute(0,2,1), real)\n",
    "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
    "    loss_ = mask * loss_\n",
    "\n",
    "    return torch.sum(loss_)/torch.sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    accuracies = torch.logical_and(mask, accuracies)\n",
    "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
    "    mask = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    return torch.sum(accuracies)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    src = batch_item['src_token'].to(device)\n",
    "    tar = batch_item['tar_token'].to(device)\n",
    "    \n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    if training is True:\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        return loss, acc, round(lr, 10)\n",
    "    else:\n",
    "        transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:15,  5.71it/s, Epoch=1, LR=0.0001, Loss=3.466304, Total Loss=3.972029, Total ACC=0.158188]\n",
      "7it [00:00,  7.91it/s, Epoch=1, Val Loss=6.593642, Total Val Loss=3.168485, Total Val ACC=0.322829]\n",
      "88it [00:15,  5.77it/s, Epoch=2, LR=0.0001, Loss=1.846326, Total Loss=2.493635, Total ACC=0.400300]\n",
      "7it [00:00,  7.98it/s, Epoch=2, Val Loss=6.191784, Total Val Loss=2.658662, Total Val ACC=0.424855]\n",
      "88it [00:15,  5.76it/s, Epoch=3, LR=0.0001, Loss=1.743453, Total Loss=2.115055, Total ACC=0.470134]\n",
      "7it [00:00,  8.07it/s, Epoch=3, Val Loss=5.950694, Total Val Loss=2.425170, Total Val ACC=0.466345]\n",
      "88it [00:15,  5.71it/s, Epoch=4, LR=0.0001, Loss=2.999063, Total Loss=1.911702, Total ACC=0.502446]\n",
      "7it [00:00,  8.09it/s, Epoch=4, Val Loss=5.798476, Total Val Loss=2.294058, Total Val ACC=0.487002]\n",
      "88it [00:15,  5.70it/s, Epoch=5, LR=0.0001, Loss=0.940769, Total Loss=1.749979, Total ACC=0.531091]\n",
      "7it [00:00,  7.83it/s, Epoch=5, Val Loss=5.741198, Total Val Loss=2.215653, Total Val ACC=0.499172]\n",
      "88it [00:15,  5.70it/s, Epoch=6, LR=0.0001, Loss=1.152017, Total Loss=1.637188, Total ACC=0.550628]\n",
      "7it [00:00,  8.21it/s, Epoch=6, Val Loss=5.629330, Total Val Loss=2.137610, Total Val ACC=0.517930]\n",
      "88it [00:15,  5.73it/s, Epoch=7, LR=0.0001, Loss=1.593732, Total Loss=1.539270, Total ACC=0.570587]\n",
      "7it [00:00,  7.61it/s, Epoch=7, Val Loss=5.550153, Total Val Loss=2.083204, Total Val ACC=0.524336]\n",
      "88it [00:15,  5.72it/s, Epoch=8, LR=0.0001, Loss=1.374556, Total Loss=1.450009, Total ACC=0.584552]\n",
      "7it [00:00,  7.49it/s, Epoch=8, Val Loss=5.543182, Total Val Loss=2.055328, Total Val ACC=0.532265]\n",
      "88it [00:15,  5.76it/s, Epoch=9, LR=0.0001, Loss=0.858317, Total Loss=1.369580, Total ACC=0.600662]\n",
      "7it [00:00,  7.84it/s, Epoch=9, Val Loss=5.461508, Total Val Loss=2.013046, Total Val ACC=0.538516]\n",
      "88it [00:15,  5.80it/s, Epoch=10, LR=0.0001, Loss=1.064156, Total Loss=1.297144, Total ACC=0.614985]\n",
      "7it [00:00,  7.93it/s, Epoch=10, Val Loss=5.502833, Total Val Loss=1.997527, Total Val ACC=0.543558]\n",
      "88it [00:15,  5.59it/s, Epoch=11, LR=0.0001, Loss=0.746713, Total Loss=1.224641, Total ACC=0.629227]\n",
      "7it [00:00,  7.42it/s, Epoch=11, Val Loss=5.517734, Total Val Loss=1.995280, Total Val ACC=0.545438]\n",
      "88it [00:15,  5.51it/s, Epoch=12, LR=0.0001, Loss=0.787017, Total Loss=1.158882, Total ACC=0.643358]\n",
      "7it [00:00,  7.68it/s, Epoch=12, Val Loss=5.437868, Total Val Loss=1.954236, Total Val ACC=0.557441]\n",
      "88it [00:15,  5.58it/s, Epoch=13, LR=0.0001, Loss=1.579695, Total Loss=1.099639, Total ACC=0.657034]\n",
      "7it [00:00,  7.36it/s, Epoch=13, Val Loss=5.485535, Total Val Loss=1.948701, Total Val ACC=0.563225]\n",
      "88it [00:15,  5.69it/s, Epoch=14, LR=0.0001, Loss=1.002500, Total Loss=1.035959, Total ACC=0.672703]\n",
      "7it [00:00,  7.79it/s, Epoch=14, Val Loss=5.532869, Total Val Loss=1.947273, Total Val ACC=0.560083]\n",
      "88it [00:15,  5.71it/s, Epoch=15, LR=0.0001, Loss=0.894137, Total Loss=0.977895, Total ACC=0.685977]\n",
      "7it [00:00,  7.94it/s, Epoch=15, Val Loss=5.524209, Total Val Loss=1.941378, Total Val ACC=0.567791]\n",
      "88it [00:15,  5.76it/s, Epoch=16, LR=0.0001, Loss=0.699337, Total Loss=0.921131, Total ACC=0.700389]\n",
      "7it [00:00,  7.58it/s, Epoch=16, Val Loss=5.498278, Total Val Loss=1.934544, Total Val ACC=0.568034]\n",
      "88it [00:15,  5.76it/s, Epoch=17, LR=0.0001, Loss=1.055353, Total Loss=0.865453, Total ACC=0.715855]\n",
      "7it [00:00,  7.71it/s, Epoch=17, Val Loss=5.510827, Total Val Loss=1.927298, Total Val ACC=0.569969]\n",
      "88it [00:15,  5.70it/s, Epoch=18, LR=0.0001, Loss=0.879042, Total Loss=0.816318, Total ACC=0.728887]\n",
      "7it [00:00,  7.97it/s, Epoch=18, Val Loss=5.532415, Total Val Loss=1.922155, Total Val ACC=0.573544]\n",
      "88it [00:15,  5.74it/s, Epoch=19, LR=0.0001, Loss=1.247658, Total Loss=0.773621, Total ACC=0.741096]\n",
      "7it [00:00,  7.69it/s, Epoch=19, Val Loss=5.579321, Total Val Loss=1.947952, Total Val ACC=0.571821]\n",
      "88it [00:15,  5.79it/s, Epoch=20, LR=0.0001, Loss=0.664814, Total Loss=0.722158, Total ACC=0.756905]\n",
      "7it [00:00,  7.40it/s, Epoch=20, Val Loss=5.730156, Total Val Loss=1.969747, Total Val ACC=0.570931]\n"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "acc_plot, val_acc_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gc.collect()\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'LR' : lr,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    acc_plot.append(total_acc/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_acc_plot.append(total_val_acc/(batch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot, label='train_loss')\n",
    "plt.plot(val_loss_plot, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU5Z348c839xAg5EowARIgEK6ChouIgHfU1kutgq222lZq672723Wr27q2+1vbbt1tt9bWWrfinbXF0hbFyk1RQcBySSCEEAhJSMiN3EhCkpnn98c5CUOYQICcTDLn+3698ppzeWbmy2Hm+c55nnOeR4wxKKWUcq+QQAeglFIqsDQRKKWUy2kiUEopl9NEoJRSLqeJQCmlXC4s0AGcrcTERJOenh7oMJRSakDZtm1blTEmyd++AZcI0tPT2bp1a6DDUEqpAUVEirrbp01DSinlcpoIlFLK5TQRKKWUyw24PgJ/2traKCkpoaWlJdChDFhRUVGkpaURHh4e6FCUUn0sKBJBSUkJQ4YMIT09HREJdDgDjjGG6upqSkpKyMjICHQ4Sqk+FhRNQy0tLSQkJGgSOEciQkJCgp5RKeVSQZEIAE0C50mPn1LuFTSJQCmlgpExhr3lDfzX3/LJK6935D2Coo9AKaWCiTGG3MP1vJNTxju7yimsOoYIJA6JJCtlaK+/nyaCXlBbW8trr73Gt7/97bN63vXXX89rr73GsGHDHIpMKTVQeL2G7SW1vJtTzjs5ZRTXNBMaIlwyJoGvzcvgmsnDSR4S5ch7ayLoBbW1tfzqV786JRG0t7cTFtb9IV61apXToSml+jGP17Ct6CirdpWxOrecsroWwkOFS8cl8uDlmVw1aTjxMRGOxxF0ieDf/pzL7sO924426YKh/ODzk7vd/9hjj7F//36mT59OeHg4UVFRxMXFkZeXR35+PjfffDPFxcW0tLTw8MMPs3TpUuDEuEmNjY1cd911zJs3j48//pjU1FT+9Kc/ER0d7ff9fvvb3/L888/T2trKuHHjePnllxk0aBBHjhzhvvvuo7CwEIDnnnuOuXPnsmzZMv7zP/8TEWHatGm8/PLLvXp8lFI91+7xsvlAjV35H6Gq8TgRYSEsGJ/EdxdN4Iqs4cRG9+39PEGXCALh6aefJicnh+3bt7N+/XpuuOEGcnJyOq/Jf/HFF4mPj6e5uZmZM2dy6623kpCQcNJr7Nu3j9dff53f/va33H777fzhD3/gzjvv9Pt+X/jCF7j33nsBeOKJJ/jd737Hgw8+yEMPPcSCBQtYsWIFHo+HxsZGcnNz+dGPfsTHH39MYmIiNTU1zh4MpdQpjh1v59MDNbybU857u8s52tRGdHgoV2Qls2hKCpdnJTM4MnDVcdAlgtP9cu8rs2bNOunGrF/84hesWLECgOLiYvbt23dKIsjIyGD69OkAXHzxxRw8eLDb18/JyeGJJ56gtraWxsZGrr32WgDWrl3LsmXLAAgNDSU2NpZly5Zx2223kZiYCEB8fHyv/TuVUv41tbaz9eBRNhVW80lhNbtK6mj3GgZHhnHVxGQWTRnBgvFJREeEBjpUIAgTQX8QExPTubx+/Xref/99PvnkEwYNGsTChQv93rgVGRnZuRwaGkpzc3O3r3/33Xfz9ttvc+GFF/L73/+e9evX92r8Sqmz09zqYVvRiYp/R3Et7V5DWIgwLS2Wby4Yw5wxCczKiCcyrH9U/r40EfSCIUOG0NDQ4HdfXV0dcXFxDBo0iLy8PDZt2nTe79fQ0MCIESNoa2vj1VdfJTU1FYArr7yS5557jkceeaSzaeiKK67glltu4Tvf+Q4JCQnU1NToWYFS56mlzcNnRUf5pLCaTYXVbC+upc1jCLUr/nvnj+GSMQlcPDqOmAA2+fRU/49wAEhISODSSy9lypQpREdHM3z48M59ixYt4te//jUTJ05kwoQJzJkz57zf74c//CGzZ88mKSmJ2bNndyahn//85yxdupTf/e53hIaG8txzz3HJJZfw+OOPs2DBAkJDQ5kxYwa///3vzzsGpdzkeLuHz4pqT1T8h2pp9XgJDRGmpMby9XljmDMmnuz0+IC29Z8rMcYEOoazkp2dbbrOULZnzx4mTpwYoIiChx5HpSzGGPLKG9i4r4qNBVV8eqCG5jYPIQJTUmO5ZEwCc8YkkJ0ex5CogTFir4hsM8Zk+9s38FKXUko5oLyuhQ/3VfJRQRUbC6qpajwOwNikGBbPHMm8cYnMGhPP0AFS8Z8NTQT92P33389HH3100raHH36Ye+65J0ARKRU8Go+3s2l/NRsLrF/9BRWNACQOjuDScYnMG5fIvMxERsT6v58nmGgi6MeeffbZQIegVNBo93jZUVLLxn3VbCyo5O+HrCt7osJDmJWRwOLskczLTGTC8CGEhLhrNF5NBEqpoNXU2s6GvZWszi1nTV4FDS3tiMDU1FiWzh/DvMxELhoVR1R4/7uksy9pIlBKBZXaplbW7Kng3dxyPsiv5Hi7l7hB4SyanMLCCcnMHZtAXB+M3zOQaCJQSg14FfUtrN59hNU55WwqrKbdaxgRG8Uds0Zx7eQUZqbHERaq0690x9FEICKLgJ8DocALxpinu+z/L+Bye3UQkGyM0TGZlVJnVFR9jNW55bybU85nh2oBGJMYw73zx7BocgrT0mJ15r0eciwRiEgo8CxwNVACbBGRlcaY3R1ljDGP+pR/EJjhVDz9yeDBg2lsbAx0GEoNKB3X9r+bU87q3HLyyq0bKaekDuUfrh7PoikpjEserJX/OXDyjGAWUGCMKQQQkTeAm4Dd3ZS/A/iBg/EopQaY1nYvWw7WsGZPBWvyjlBU3YQIzBwdzxM3TOTaySmMjB8U6DAHPCcTQSpQ7LNeAsz2V1BERgMZwNpu9i8FlgKMGjXq9O/6zmNQvuvsoz2dlKlw3dPd7n7ssccYOXIk999/PwBPPvkkYWFhrFu3jqNHj9LW1saPfvQjbrrppjO+VWNjIzfddJPf5/mbV6C7OQiUGqiqGo+zfm8la/OO8EF+FY3H24kIC2Hu2ATuWzCWqyYOJ2lI5JlfSPVYf+ksXgK8ZYzx+NtpjHkeeB6sISb6MrCeWLx4MY888khnIli+fDmrV6/moYceYujQoVRVVTFnzhxuvPHGM562RkVFsWLFilOet3v3br/zCvibg0CpgcQYw56yBtbmHWFNXgXbi2sxBoYPjeTzF17AlVnJzB2XwKCI/lJdBR8nj2wpMNJnPc3e5s8S4P5eedfT/HJ3yowZM6ioqODw4cNUVlYSFxdHSkoKjz76KB988AEhISGUlpZy5MgRUlJSTvtaxhi+973vnfK8tWvX+p1XwN8cBEr1dy1tHj7eX8WaPRWszaugrM4amv3CkcN49KrxXJGVzOQLhmp7fx9xMhFsATJFJAMrASwBvtS1kIhkAXHAJw7G4rjbbruNt956i/LychYvXsyrr75KZWUl27ZtIzw8nPT0dL/zEHR1rs9Tqr8rq2tmbV4Fa/dU8NH+KlravAyKCOWyzEQevWo8C7OSHJucXZ2eY4nAGNMuIg8Aq7EuH33RGJMrIk8BW40xK+2iS4A3zEAbBrWLxYsXc++991JVVcWGDRtYvnw5ycnJhIeHs27dOoqKinr0OnV1dX6f1928Av7mINCzAtUfNLd62Hygmg/3VfHhvkryj1jNliPjo1kycxRXZCUze0z/nKjFbRxtdDPGrAJWddn2/S7rTzoZQ1+ZPHkyDQ0NpKamMmLECL785S/z+c9/nqlTp5KdnU1WVlaPXqe7502ePNnvvALdzUGgVF/zeg17yus7K/4tB47S6vESERbC7Ix4br0ojSuykvUSz35I5yNQnfQ4qrNVUd/SWfFvLKiiqrEVgKyUIVyWmchlmUnMyoh3/Vg+/YHOR6CU6hUtbR4+PVDDh/sq+XBfVedNXQkxEZ0V/7zMRIYP1bb+gUQTQYDs2rWLu+6666RtkZGRbN68OUARKeVfxzg+7+WWs/lADa3tXiJCQ5iZEcdj12VxWWYiE1OGum7o5mASNInAGDOg2h2nTp3K9u3bAx1Gp4HWRKicVVzT1DmOz7ZDRzHGGsfnztmjmT8+kdkZCURHaHNPsAiKRBAVFUV1dTUJCQkDKhn0F8YYqquriYrS03k321/ZyLs5VuW/q7QOgIkjhvLoVdY4PpnayRu0giIRpKWlUVJSQmVlZaBDGbCioqJIS0sLdBiqD3Xc0ftubjnv5pR1Xt45feQw/uW6LK6dnEJ6YkyAo1R9ISgSQXh4OBkZGYEOQ6l+zxjD9uJau/Ivp6i6iRCBmenxPPn5SVwzOYULhgX/HL3qZEGRCJRS3Wtp87D5QA3r8ipYnVtOWV0LYSHC3HGJ3LdgLFdPGk7iYB3Ezc00ESgVZIwxHKg6xob8SjbkV7KpsJqWNi+RYSHMH5/EP107gSuzhhM7KDzQoap+QhOBUkHg2PF2Pt5fzYb8CjbkV1Jc0wzAmKQY7pg1igXjk5gzJkFv7FJ+aSJQagAyxrD3SAMb9lq/+rccrKHNYxgUEcrcsYksnT+WheOTdNIW1SOaCJQaIOqa29i4r6rzV/+R+uOANZzD1+ZlsGB8Etmj44kI00na1dnRRKBUP9Xxq39tXgXr8yrZdugoHq9haFQYl2UmsWB8EvPHJ5ESq/d/qPOjiUCpfqSptZ2PCqpZt7eC9XkVHLYnbJl8wVC+tWAsCyckMX3kMMJC9Ve/6j2aCJQKsKLqY9aELXkVbC6sodXjJSYilHmZiTx8VSYLJyTrIG7KUZoIlOpjre1ethysYW1eBevyKiisOgZYV/h85ZLRXJ6VzMx0betXfUcTgVJ94Eh9C+vyKli3t4KN+6o41uohIiyEOWMSOiv/0Qk6nIMKDE0ESjnA4zXsKKllnd3kk3u4HoALYqO4eUYql09IZu64BAZF6FdQBZ5+CpXqJXXNbXy4r5K1eypYn19JzbFWQgQuHh3HdxdN4IqsZCYMH6IjeKp+RxOBUufIGENBRWNnR+/WIuvyzmGDwlk4PonLs5JZMD6JYYMiAh2qUqeliUCps9DS5uGTwurOJp+So9ZQDlkpQ/jm/DFckZXMjFFxhOpsXWoA0USg1BmU1TV3XuGzsaCKljYvUeEhzBuXyLcWjuXyCck6dLMa0DQRKNWFx2uN2b8ur4I1eRXsKbM6elOHRXN79kguz0rmEh3ATQURTQRKAfUtbXyQX2kN57DX6ugNDREuHmVN0H5FVrJO1aiClqOJQEQWAT8HQoEXjDFP+ylzO/AkYIAdxpgvORmTUmB19BZWHWPtHqutf8vBGtq1o1e5lGOJQERCgWeBq4ESYIuIrDTG7PYpkwn8C3CpMeaoiCQ7FY9Sre1ePj1Qw5q8I6zNq6CougmwOnrvnT+GK7OSdRwf5UpOnhHMAgqMMYUAIvIGcBOw26fMvcCzxpijAMaYCgfjUS7U0uZh/d4K/rqrnHV5FTQebycyLIS5YxP4xmVjuHxCEmlxOma/cjcnE0EqUOyzXgLM7lJmPICIfITVfPSkMebdri8kIkuBpQCjRo1yJFgVPJpbOyr/MtbmVdDU6iE+JoLPTRvB1ZOGM3dsItER2tGrVIdAdxaHAZnAQiAN+EBEphpjan0LGWOeB54HyM7ONn0dpOr/mls9rLMr/3V25Z8QE8HNM1K5YeoIZmfEa5OPUt1wMhGUAiN91tPsbb5KgM3GmDbggIjkYyWGLQ7GpYJEU2s76/IqWWX/8m9u85A4OIJb7Mp/llb+SvWIk4lgC5ApIhlYCWAJ0PWKoLeBO4D/FZFErKaiQgdjUgNcU2s7a/MqWLWrjHV5lZ2V/60Xp3L91BHMzkjQu3qVOkuOJQJjTLuIPACsxmr/f9EYkysiTwFbjTEr7X3XiMhuwAP8kzGm2qmY1MBU2XCcDfmVrNlzhHV7K2hp85I4OJIvXpzG9fYvf638lTp3YszAanLPzs42W7duDXQYykEdQzivz7NG8dxZUgdA0pBIFk1O4YZpI5iZrpW/UmdDRLYZY7L97Qt0Z7FSANQca+WD/ErW761gQ34lR5vaCBGYMSqOf7xmPAsnJDNpxFBCtPJXqtdpIlAB4fUacg7XsS6vkvX5FWwvrsUYSIiJ4PIJySzMSmZ+ZqLe2atUH9BEoPpMXVMbH+yrZP3eSjbkV1DV2IoITEsbxsNXZnL5hGSmpsbqr37lPK8HmmuhuQaaavw8Hj15uakGWmohJAzCoiA8CsKifR7tv7AoP49RED7IWg4Nh5Bw+zG0m2V7vXM5DELDrOXoYRDR+1OaaiJQjvJ6DRsLqnhlUxFr8io6J26Zn5nE5VlJzM9MImFwZKDDVH3heAN42sAYMF7A9HwZrMq7vQXamqHtmP3YDG1NJx5bm3zWO/bZ663HTlTwLXXdxymhMCgeouMgOh6GjYIR0yEqFozHeq2OODoeWxvhWBW0N0Nbi/WeHfvoxX7YG34GM7/Re69n00SgHHH0WCtvbSvh1c1FHKxuIj4mgq/Py+DaySlMHzlMO3qDldcL9aVQtRcq86HK5+9YZR8EINav7/DoE48Rg6zlQfEQP8au5ONPPEbHwaC4E9sih0JvjTJrDHhaTyQNTxt426yk1rHsaQdvu71s7+tc7lJ25JzeiasLTQSq1xhjjeP/yqZD/HnnYVrbvWSPjuORq8Zz3dQUIsN0WIc+Y4xV8dYVQ20x1JVAYzmEx1i/bKOHWY9Rw3zW7WaHnlSC7a1QU9ilwt8LVQXWr/UO0XGQOAHGL4KEcVbFjFjvIeKzHHJiGXu9634JOdHk0lnJx5y8HhbVe5V4bxCBsEjrrx/TRKDOW1NrOyu3H+blTUXkHq4nJiKU27PT+PLs0UwcMTTQ4QWn9laoL7Eq+I6Kvu7Qyeue4yc/JzTy1G1dhYTZCcJPkgiPhqNFVoVfc8BqJukQOxISx8NFcyFpvFX5J46HmMT+VTErvzQRqHNWUNHAK5sO8YfPSmhoaWfC8CH88OYp3DIjlcGR+tHqFV4vVOyGgxuhZAvUFlmVfEM5p7Q9D06B2DQYMQ2yrofYUdb6sJHWY9Qwq939eL3VUdpSa7WVN9uPLbUnL3fsqyu2lluPWRV+8kSYdDMkTYDETEjIhMjBATk8qnfot1WdldZ2L+/tLueVTUVsKqwhIjSE66amcOec0WSPjtMZvM6X1wNHcuDgR1blf+hjq4MTYGgaJIyFsVeeqNxjOx7Tetb8IKF2J2ics/8ONaBoIlA9UnK0iTe3FPP6p8VUNR4nLS6a7y6awO3ZI0nUq37OnacdyndC0UdW5V/0MRy3r2iJS4esG2D0PEi/1Lp6RSkHaCJQ3Wr3eFm/t5JXNxexPt+64uOKCcncOWc088cn6ZU/58LTDmU74OCHVuV/aJPVVAMQPxYm3wzp82D0pRCbGthYlWtoIlCnKKtr5s0txby5pZiyuhaShkRy/8JxLJ45kpHxLp3Nyxir3by16dRr130f21u639dUDSVbrWvOwepMnXLriYp/6IjA/huVa2kiUIA10NsH+ZW8uvkQa/OO4DVwWWYiP/j8JK6cOJzwYB7Xv7UJGsqsv/oyaDhsdcbW248d657Ws3td30sdw6IgcghcuORExT9Yp+hW/YMmAperqG/hzS3FvLGlmNLaZhIHR/DNBWO5Y+YoRiUEwa//1iaoPWRdbVN7yKey96n4j/u5yzQ8xvqFPmSEdRPP0BEweDhEDPa5YSm6y7Lv9ezREBLEyVMFFU0ELuT1Gj4sqOK1zUW8v8ca9uHScQl87/qJXD1pOBFhA6gC87TZ184XWde4d308VnFyeQmFISnWX8I4yJhvr19wouIfMsL69a5XQCmX0ETgIpUNx1m+tZg3thyiuKaZ+JgIvjEvgyWzRpGR2PsDWfWa1mP2nav74OjBkyv6+tKTb2ySUKuTddhoGH8NDEuHuNHW+rBRVnNMiN7hrJQvTQQuUNfcxn+/n88rm4po8xhmZ8Tzj9dMYNGUfjbsQ0udNVxBZZ79t9f6qzt0crnBKVblPmrOiUo+zq7oh6ZZIzUqpXpMvzFBzOs1vLWthB+/m0dNUytLZo7k6/PGMC45wHeBHqu2Kvoqu6LvqPQbyk6UCYuy7lodOQsu+op9F+t4q8IPjw5c7EoFIU0EQWp7cS0/WJnLjuJaLh4dx0s3zmJKamzfvLkx1pC8tUV2U84B67HmgFXhN1WdKBseY1XyYxZaj0lZ1uOw0dqEo1Qf0UQQZKoaj/OTd/NYvrWEpCGRPHP7hdwyI7X3h35oa7auwjl68ES7fefywZNHoATripu4dJhwnV3Z2xX+0FS9ukapANNEECTaPV5e3lTEM3/Lp7nVw9L5Y3jwinEMiQrvhRdvhfx3Ye871tDDtUUnN+OAddnksNFWZZ8x33qMSz/Rdu/ArEpKqd6hiSAIfLK/midX5rL3SIN9E9jk3ukHqNwLny2DHW9YzTmDEq1f8mOvtCr4zso+HWKS9HJLpQYoTQQD2OHaZv591R7+urOMtLhofnPXxVwzafj5NQMdb4DcFfDZy1DyqTU+/YTrYMZXYNyV2m6vVBDSRDAAtbR5eOHDQp5dtx+vMTxyVSb3LRhLVPg5VtLGQPGn8PdlkLPCat9PnADX/AimLYHBSb37D1BK9SuOJgIRWQT8HAgFXjDGPN1l/93AT4FSe9MvjTEvOBnTQLdmzxGe+stuiqqbWDQ5hcdvmHjuA8E1VsCO1+Hvr1g3bEUMhilfsC7XTJupTT1KuYRjiUBEQoFngauBEmCLiKw0xuzuUvRNY8wDTsURLIprmvj+n3JYt7eSsUkxvPL12czLTDz7F/K0Q8H78PeXrQ5gbzuMnA03/hIm36IzTSnlQk6eEcwCCowxhQAi8gZwE9A1EajT8HoNr24u4j/eySNEhCdumMhX56af3WignjY4vB32rrLOABrKrM7dOd+CGXdZl3EqpVzLyUSQChT7rJcAs/2Uu1VE5gP5wKPGmOKuBURkKbAUYNQo98zSVFzTxD+9tYNNhTXMH5/E01+YygXDenBXbUfFf/BDe7rDTVa7v4TAuKvh+p/C+EUQ2guXliqlBrxAdxb/GXjdGHNcRL4JvARc0bWQMeZ54HmA7Oxs03V/sPF6Da9sLuLpd/IIFeHHt07l9uyR3V8N5GmHsi4Vf8fkJ0kTYfqXrDHw0+dBzDk0JymlgpqTiaAUGOmznsaJTmEAjDHVPqsvAD9xMJ4B4VB1E9/9wxnOAnynOzy4EQ594lPxZ9mTn1xmT36iV/wopU7PyUSwBcgUkQysBLAE+JJvAREZYYzpuEX1RmCPg/H0a16v4eVN1llAWIifs4DaYsj9o1XxF30CrQ3W9s6KX2e9UkqdG8cSgTGmXUQeAFZjXT76ojEmV0SeArYaY1YCD4nIjUA7UAPc7VQ8/dmhaqsvYPOBLmcBxsCBD+HT30DeX8F4rev7p91+oqlHK36l1HkSYwZWk3t2drbZunVroMPoFV3PAv71c5O4LTsNaWuCncvh0+ehYjdEx8FFX4Xsr1lDOyil1FkSkW3GmGx/+wLdWexaRdXH+O5bO9l8oIYF45P4jy9M5QJvObz3hHWNf0sdpEy1ru+f+kUdg18p5RhNBH3M6zUs++QgP353L2Ehwk9uncptcQXIqnusG7wkBCbdCLO+ac3ApXf3KqUc1qNEICK3AGuNMXX2+jBgoTHmbSeDCzZF1cf4p7d28umBGq4dF8NPMnOJ3fQ4VO+zbvCa/49W88/QCwIdqlLKRXp6RvADY8yKjhVjTK2I/ADQRNBDH+RX8s2XtzE2pIz3sraQeXglUtIAF1wEt/zGGt4hLDLQYSqlXKinicDfeAbarNRD1Y3H+Z83/8KyyGXMbP8MDoVbFf/sb0Ka374bpZTqMz2tzLeKyDNYg8gB3A9scyak4GKMYdkr/8uL7U8SHR0N874HF98NQ4YHOjSllAJ6nggeBP4VeBMwwN+wkoE6g21//G8eLHuKusFjGHLv2zBs5JmfpJRSfahHicAYcwx4zOFYgovXS/1fHid716/4e1Q20x74I0THBjoqpZQ6RY/GMhaRv9lXCnWsx4nIaufCGuBamzDL72LoZ7/idXMNSUtXEKpJQCnVT/V0UPtEY0xtx4ox5iigYxv403AEfn8D5P2Vp9ruIvzzz5CWMDTQUSmlVLd6mgi8ItI5EYCIpGP1FShfR3LhhSvxVuzhvvbvcDjrHm69OC3QUSml1Gn1tLP4cWCjiGwABLgMe6IYZdv3Pvzf3ZiIwTwU9f/Yxije+8LU7ucQUEqpfqJHZwTGmHeBbGAv8DrwD0Czg3ENLFtegNduh7h0fjnuN/ylajg//eI04mMiAh2ZUkqdUU+HmPgG8DDW5DLbgTnAJ/iZTcxVvB54719h07OQeS2bL/5PnnlpF1+ePYrLs7QLRSk1MPS0j+BhYCZQZIy5HJgB1J7+KUGu9Ri8eaeVBGbfR/0ty/jO2wWMjh/E4zdMDHR0SinVYz3tI2gxxrSICCISaYzJE5EJjkbWn9WXweuLoXwXXPcTmP1N/m35DsrrW3jrvksYFKGjbyilBo6e1lgl9n0EbwN/E5GjQJFzYfVj5bvgtcXWfAF3vAHjr+WdXWX84bMSHroykxmj4gIdoVJKnZWe3ll8i734pIisA2KBdx2Lqr/Kfw/eugcih8LX3oWUqVTUt/C9FbuYlhbLg1eMC3SESil11s66DcMYs8GJQPq9/NXw+hJr1rA73oShIzDG8N0/7KSp1cMzt08nPLSnXS5KKdV/aGN2TxgDa56C+LFwzzsQEQPAq5sPsX5vJf9242TGJQ8OcJBKKXVu9CdsT+x7D47kwGX/0JkECisb+fe/7uGyzETumqMTyiulBi5NBGdiDHz4M4gdZU0iD7R7vDy6fAcRYSH89IsXEhKidw8rpQYuTQRnUvQxFG+GSx+C0HAAfrV+PzuKa/n3W6aQEhsV4ACVUur8aCI4kw9/Zk0sP+NOAHYU1/LzNfu4efoFfG6aTjKvlBr4HE0EIrJIRPaKSIGIdDuxjYjcKiJGRPrXBL6H/w7718Al90N4NM2tHh5dvp3kIZH8201TAh2dUkr1CscSgYiEYs1xfB0wCbhDRCb5KY8nuOQAAA9mSURBVDcEawiLzU7Fcs4+fAYiYyH76wA8/c4eCiuP8bPbLiQ2OjzAwSmlVO9w8oxgFlBgjCk0xrQCbwA3+Sn3Q+DHQIuDsZy9ynzY82eYdS9EDWVTYTUvfVLE1y7NYO64xEBHp5RSvcbJRJAKFPusl9jbOonIRcBIY8xfT/dCIrJURLaKyNbKysrej9Sfj/4bwqJgzrcAeC/3CFHhIXx3kXuHWFJKBaeAdRaLSAjwDNbcBqdljHneGJNtjMlOSkpyPrjaQ7DzTbj4boixfv3nlNYx+YJYosJDnX9/pZTqQ04mglJgpM96mr2twxBgCrBeRA5izXGwsl90GH/8P4DA3AcA8HgNOYfrmJqqE9ArpYKPk4lgC5ApIhkiEgEsAVZ27DTG1BljEo0x6caYdGATcKMxZquDMZ1ZYwV8tgwuXAyx1nzDB6oaaWr1MEUTgVIqCDmWCIwx7cADwGpgD7DcGJMrIk+JyI1Ove952/QctB+HSx/t3LSrtA6AaWmaCJRSwcfRQeeMMauAVV22fb+bsgudjKVHmmut+Ycn3wyJJ4aU3llSR3R4KGOTdGA5pVTw0TuLfW15AY7Xw7xHT9qcU1rHpAuGEqpjCimlgpAmgg6tTbDpVzDuahhxYedmj9eQe7heO4qVUkFLE0GHv78MTdXWUNM+CiutjmJNBEqpYKWJAKC9FT76BYyaC6MvOWlXR0fxVO0oVkoFKU0EALuWQ30JXPadU3eVakexUiq4aSLwemDjf1lzEY+76pTd1h3F2lGslApemgj2/BmqC6y+ATm5svd4DTml9XojmVIqqLk7EXRMQ5kwDiaeeo9bYWUjzW3aUayUCm7uTgQFa6B8J1z6CIScOpicdhQrpdzA3Yngw5/B0FSYttjvbr2jWCnlBu5NBEWfwKGPYe5DEBbht4h2FCul3MC9iWDjMzAoAS76it/dHXcUa0exUirYuTMRlO2Efe9Zs49FDPJbZL/dUawjjiqlgp07E8HGZyBiCMy8t9siu0rsjmI9I1BKBTn3JYKqAsh9G2Z9A6KHdVtsV2kdgyJCGaMdxUqpIOe+RPDRf0NYJMz59mmL7SqtY9II7ShWSgU/dyWCuhLY8QbMuAsGJ3dbzOM17D5cr/cPKKVcwV2J4ONfAgYufei0xfbrHcVKKRdxTyI4VgWfvQRTb4dho05bVDuKlVJu4p5E8Onz0NYM8x45Y1HtKFZKuYmjk9f3K3O+BUkTrL8z2KV3FCulXMQ9ZwTRcTDl1jMWa/d42a13FCulXMQ9iaCH9lce0zuKlVKuoomgi86hp/WMQCnlEo4mAhFZJCJ7RaRARB7zs/8+EdklIttFZKOITHIynp7IsTuKMxK1o1gp5Q6OJQIRCQWeBa4DJgF3+KnoXzPGTDXGTAd+AjzjVDw9tbOkVjuKlVKu4uQZwSygwBhTaIxpBd4AbvItYIyp91mNAYyD8ZxRu8fL7rJ6pqZ2PwaRUkoFGycvH00Fin3WS4DZXQuJyP3Ad4AI4Ap/LyQiS4GlAKNGnf5msPOxv/IYLW1epqYNdew9lFKqvwl4Z7Ex5lljzFjgn4EnuinzvDEm2xiTnZSU5FgsO0tqAe0oVkq5i5OJoBQY6bOeZm/rzhvAzQ7Gc0Y5pXXEaEexUsplnEwEW4BMEckQkQhgCbDSt4CIZPqs3gDsczCeM7LuKI7VjmKllKs4lgiMMe3AA8BqYA+w3BiTKyJPiciNdrEHRCRXRLZj9RN81al4zqSjo1jvKFZKuY2jYw0ZY1YBq7ps+77P8sNOvv/ZKKhs1I5ipZQrBbyzuL84MfS0XjqqlHIXTQS2jo7iMYkxgQ5FKaX6lCYC2067ozhEO4qVUi6jiQCro3hPmc5RrJRyJ00E+HQU6xVDSikX0kQA7LQ7ivXSUaWUG2kiQDuKlVLupokA+47iVO0oVkq5k+sTQcccxdo/oJRyK9cngn0VjRxv145ipZR7uT4RdM5RrJeOKqVcyvWJIKe0jsGRYWQkaEexUsqdXJ8IdpbUMemCodpRrJRyLVcngo47iqdp/4BSysVcnQg6O4q1f0Ap5WKuTgS79I5ipZRyeSLQjmKllNJEMFk7ipVSLufaRNBmz1GsN5IppdzOtYlg35FGWrWjWCml3JsIcjruKNYzAqWUy7k2EewsrWVwZBjp2lGslHI51yaCXaX12lGslFK4NBG0dcxRrM1CSinlbCIQkUUisldECkTkMT/7vyMiu0Vkp4isEZHRTsbTQTuKlVLqBMcSgYiEAs8C1wGTgDtEZFKXYn8Hso0x04C3gJ84FY+vXaW1gHYUK6UUOHtGMAsoMMYUGmNagTeAm3wLGGPWGWOa7NVNQJqD8XTquKNYO4qVUsrZRJAKFPusl9jbuvN14B1/O0RkqYhsFZGtlZWV5x3YrtJ6pqRqR7FSSkE/6SwWkTuBbOCn/vYbY543xmQbY7KTkpLO6720o1gppU4W5uBrlwIjfdbT7G0nEZGrgMeBBcaY4w7GA0D+kQZa27064qhSStmcPCPYAmSKSIaIRABLgJW+BURkBvAb4EZjTIWDsXTquKN4Wtqwvng7pZTq9xxLBMaYduABYDWwB1hujMkVkadE5Ea72E+BwcD/ich2EVnZzcv1mp0ldQyJDGN0/CCn30oppQYEJ5uGMMasAlZ12fZ9n+WrnHx/f3JK65isHcVKKdWpX3QW95XWdi97yhu0o1gppXy4KhF0dBRP1f4BpZTq5KpEoENPK6XUqVyVCHaVakexUkp15apEkFNax5TUWO0oVkopH65JBK3tXvaUNeiIo0op1YVrEkH+kQZaPXpHsVJKdeWaRKAdxUop5Z9rEkF8TARXTxquHcVKKdWFo3cW9yfXTE7hmskpgQ5DKaX6HdecESillPJPE4FSSrmcJgKllHI5TQRKKeVymgiUUsrlNBEopZTLaSJQSimX00SglFIuJ8aYQMdwVkSkEig6x6cnAlW9GE5v0/jOj8Z3/vp7jBrfuRttjEnyt2PAJYLzISJbjTHZgY6jOxrf+dH4zl9/j1Hjc4Y2DSmllMtpIlBKKZdzWyJ4PtABnIHGd340vvPX32PU+Bzgqj4CpZRSp3LbGYFSSqkuNBEopZTLBWUiEJFFIrJXRApE5DE/+yNF5E17/2YRSe/D2EaKyDoR2S0iuSLysJ8yC0WkTkS223/f76v47Pc/KCK77Pfe6me/iMgv7OO3U0Qu6sPYJvgcl+0iUi8ij3Qp0+fHT0ReFJEKEcnx2RYvIn8TkX32Y1w3z/2qXWafiHy1j2L7qYjk2f9/K0RkWDfPPe1nweEYnxSRUp//x+u7ee5pv+8OxvemT2wHRWR7N8/tk2N4XowxQfUHhAL7gTFABLADmNSlzLeBX9vLS4A3+zC+EcBF9vIQIN9PfAuBvwTwGB4EEk+z/3rgHUCAOcDmAP5fl2PdKBPQ4wfMBy4Ccny2/QR4zF5+DPixn+fFA4X2Y5y9HNcHsV0DhNnLP/YXW08+Cw7H+CTwjz34DJz2++5UfF32/wz4fiCP4fn8BeMZwSygwBhTaIxpBd4AbupS5ibgJXv5LeBKEZG+CM4YU2aM+cxebgD2AKl98d696CZgmbFsAoaJyIgAxHElsN8Yc653mvcaY8wHQE2Xzb6fs5eAm/089Vrgb8aYGmPMUeBvwCKnYzPGvGeMabdXNwFpvfmeZ6ub49cTPfm+n7fTxWfXHbcDr/f2+/aVYEwEqUCxz3oJp1a0nWXsL0MdkNAn0fmwm6RmAJv97L5ERHaIyDsiMrlPAwMDvCci20RkqZ/9PTnGfWEJ3X/5Ann8Ogw3xpTZy+XAcD9l+sOx/BrWGZ4/Z/osOO0Bu/nqxW6a1vrD8bsMOGKM2dfN/kAfwzMKxkQwIIjIYOAPwCPGmPouuz/Dau64EPgf4O0+Dm+eMeYi4DrgfhGZ38fvf0YiEgHcCPyfn92BPn6nMFYbQb+7VltEHgfagVe7KRLIz8JzwFhgOlCG1fzSH93B6c8G+v33KRgTQSkw0mc9zd7mt4yIhAGxQHWfRGe9ZzhWEnjVGPPHrvuNMfXGmEZ7eRUQLiKJfRWfMabUfqwAVmCdfvvqyTF22nXAZ8aYI113BPr4+TjS0WRmP1b4KROwYykidwOfA75sJ6pT9OCz4BhjzBFjjMcY4wV+2817B/SzaNcfXwDe7K5MII9hTwVjItgCZIpIhv2rcQmwskuZlUDH1RlfBNZ290XobXZ74u+APcaYZ7opk9LRZyEis7D+n/okUYlIjIgM6VjG6lTM6VJsJfAV++qhOUCdTxNIX+n2V1ggj18Xvp+zrwJ/8lNmNXCNiMTZTR/X2NscJSKLgO8CNxpjmrop05PPgpMx+vY73dLNe/fk++6kq4A8Y0yJv52BPoY9Fujeaif+sK5qyce6muBxe9tTWB96gCisJoUC4FNgTB/GNg+riWAnsN3+ux64D7jPLvMAkIt1BcQmYG4fxjfGft8ddgwdx883PgGetY/vLiC7j/9/Y7Aq9lifbQE9flhJqQxow2qn/jpWv9MaYB/wPhBvl80GXvB57tfsz2IBcE8fxVaA1bbe8RnsuIruAmDV6T4LfXj8XrY/XzuxKvcRXWO010/5vvdFfPb233d87nzKBuQYns+fDjGhlFIuF4xNQ0oppc6CJgKllHI5TQRKKeVymgiUUsrlNBEopZTLaSJQqg/ZI6P+JdBxKOVLE4FSSrmcJgKl/BCRO0XkU3sM+d+ISKiINIrIf4k1j8QaEUmyy04XkU0+Y/vH2dvHicj79uB3n4nIWPvlB4vIW/Z8AK/21ci3SnVHE4FSXYjIRGAxcKkxZjrgAb6MdUfzVmPMZGAD8AP7KcuAfzbGTMO6E7Zj+6vAs8Ya/G4u1p2pYI04+wgwCevO00sd/0cpdRphgQ5AqX7oSuBiYIv9Yz0aa8A4LycGF3sF+KOIxALDjDEb7O0vAf9njy+TaoxZAWCMaQGwX+9TY49NY89qlQ5sdP6fpZR/mgiUOpUALxlj/uWkjSL/2qXcuY7Pctxn2YN+D1WAadOQUqdaA3xRRJKhc+7h0Vjfly/aZb4EbDTG1AFHReQye/tdwAZjzT5XIiI3268RKSKD+vRfoVQP6S8RpbowxuwWkSewZpUKwRpx8n7gGDDL3leB1Y8A1hDTv7Yr+kLgHnv7XcBvROQp+zVu68N/hlI9pqOPKtVDItJojBkc6DiU6m3aNKSUUi6nZwRKKeVyekaglFIup4lAKaVcThOBUkq5nCYCpZRyOU0ESinlcv8f8lpyWdT+Q1oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_plot, label='train_acc')\n",
    "plt.plot(val_acc_plot, label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokens):\n",
    "    transformer.to(device)\n",
    "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
    "    output = decoder_input.unsqueeze(1).to(device)\n",
    "    enc_output = None\n",
    "    for i in range(decoder_len-1):        \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        with torch.no_grad():\n",
    "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
    "        \n",
    "        # select the last token from the seq_len dimension\n",
    "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "        \n",
    "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
    "        \n",
    "        output = torch.cat([output, predicted_id], dim=-1)\n",
    "    output = output.cpu().numpy()\n",
    "    \n",
    "    summary_list = []\n",
    "    token_list = []\n",
    "    for token in output:\n",
    "        summary = tar_tokenizer.convert(token)\n",
    "        summary_list.append(summary)\n",
    "        token_list.append(token)\n",
    "    return summary_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : 음성군 경로당 지원 조례 일부개정조례안은 경로당 이용에 대한 여건 및 특수성에 따라 기존 미등록 경로당 등록기준을 완화하고, 경로당 양곡 지원에 대한 근거를 마련하는 등 경로당 이용 어르신들의 건강증진 및 복지향상에 기여하기 위해 개정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 노인 종합 복지 관 설치 및 운영 조례 일부 개정 조례 안은 < 장애인 복지 법 >의개정에 따라 상위 법령에 따른 장애인 복지 법 >에 따라 음성군의일부를 조례를 일부 개정하고자 제정함. 해\n",
      "=================================================================================\n",
      "정답 : 음성군 군세 징수 조례 일부개정조례안과 2019년 재산세 도시지역분 적용대상 지역 고시안은 <음성군 행정기구 설치 조례>가 2019년 1월 1일 전부개정됨에 따라 변경된 사항을 조례에 반영하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 지역 혁신 협의회 운영 조례 안은 음성군의지역 발전에 대한 지역 발전에 대한 지역 발전에 대한 지역 발전에 대한 음성군의원활한 사항을 조례로 정하고자 제정하였으며 , 해당 안건은 가결됨. 음성군 지역 경\n",
      "=================================================================================\n",
      "정답 : 음성군 폐기물 관리 조례 일부개정조례안은 쓰레기처리비 대비 수수료 수입비율인 주민부담율이 낮아 청소행정의 건전 재정을 저해하고 불법반입 폐기물이 증가하는 문제가 있어 지역 실정에 맞도록 쓰레기 종량제 수수료를 조정하고자 제정함. 해당 안건은 가결 되었음.\n",
      "예측 :  음성군 지역 건설 산업 활성 화를 위해 음성군의질 향상 및 운영 조례 일부 개정 조례 안은 < 지방 자치 단체의개정과 지역 경제 활성 화에 따라 지역 경제 활성 화를 조례의안은 < 지방 자치 단체의안\n",
      "=================================================================================\n",
      "정답 : 음성군 농업기계 사후관리 출장비용 지원 조례안은 음성군 농업인의 농업생산성 향상과 경영 개선, 기계화 영농 편의 등을 제공하고 농업기계 안전사용을 도모하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 노인 종합 복지 관 설치 및 운영 조례 안은 음성군의질을 위해 제정되었음. 해당 안건은 가결됨.\n",
      "=================================================================================\n",
      "정답 : 일반농산어촌개발사업 공유재산 시설물 관리위탁 운영 동의안은 조성한 시설물의 효율적인 관리를 위해 추진위원회에 그 재산의 관리를 위탁하고자 하는 것에 동의를 구하기 위해 발의됨. 해당 안건은 가결되었음.\n",
      "예측 :  2006 년도 공유 재산 관리 계획안은 대소 도시 재생 사업을 통해 사업을 통해 사업을 추진하고 , 해당 안건은 가결됨.\n",
      "=================================================================================\n",
      "정답 : 제251회 음성군의회 제2차 정례회 제3차 본회의 개의.\n",
      "예측 :  제 273 회 제 2 차 정례회 제 3 차 본회의개의선포 . 제 3 차 본회의선포 . 제 3 차 본회의선포 . 제 3 차 본회의는 제 3 차 본회의는 제 3 차 본회의는 제 3 차 본회\n",
      "=================================================================================\n",
      "정답 : 2014년도 세입 세출예산안이 가결됨. 2014년도 기금운용계획안이 가결됨.\n",
      "예측 :  2019 년도 세입 및 세출 예산안 승인의건과 2017 년도 기금 운용 계획 승인의건이 각각 가결됨 . 2013 년도 기금 운용 계획 변경 계획안과 2016 년도 기금 운용 계획 변경 계획안과 2016 년도 기금 운용 계획 변\n",
      "=================================================================================\n",
      "정답 : 2013~2017년도 음성군 중기지방재정계획 보고. 분야별 세부사업 계획 속에 현재 진행되고 있는 사업의 보고가 누락된 부분을 시정할 것.\n",
      "예측 :  음성군 노인 복지 기금 1998 년도 음성군의계획 및 운용 계획 변경 계획안에 대한 의견 제시의건은 음성군의건은 음성군의회의 의결을 통해 지역 경제 적으로 채택됨. 음성군의회의 음성군의회의 의결을 통해 계\n",
      "=================================================================================\n",
      "정답 : 음성군 행정기구 설치 조례 일부개정조례안은 각종 시설물과 조직을 효율적으로 관리하고자 제정되었으며, 해당 안건은 가결됨. 음성군 지방공무원 정원 조례 일부개정조례안은 총액인건비 기준 정원으로 정원을 감축함으로써 신규사업 등에 따른 각종 페널티를 방지하고 기능직 등을 일반직으로 직종 개편하고자 제안함.\n",
      "예측 :  음성군 행정 기구 설치 조례 일부 개정 조례 안은 < 지방 자치 단체의행정 기구 설치 조례 >에 따라 지방 자치 단체의개정과 < 지방 자치 단체의개정에 따라 상위 법령에 따라 상위 법령에 따라 상위 법령에 관한 규\n",
      "=================================================================================\n",
      "정답 : 음성군 건축 조례 일부개정조례안은 법령에서 조례로 위임된 사무에 대하여 제도시행에 필요한 사항을 자치 실정에 맞도록 건축조례 일부를 개정하고자 제정되었으며, 해당 안건은 가결됨.\n",
      "예측 :  음성군 수도 급수 조례 일부 개정 조례 안은 < 지방세 기본법 >의개정에 따라 현행 규정되는 조문의일부를 조례의개정하고자 제정하였으며 , 해당 안건은 가결됨. 음성군 군세 감면 조례 안은 가결됨\n",
      "=================================================================================\n",
      "정답 : 12월 17일부터 12월 19일까지 휴회가 가결됨. 제4차 본회의는 12월 20일 오전 10시에 개의.\n",
      "예측 :  제 12 월 1 일부터 12 월 3 일까지 3 일 간 휴회가 가결됨 . 제 3 차 본회의는 12 월 21 일 오전 10 시에 개의.\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
    "    print('정답 :', a)\n",
    "    print('예측 :', p)\n",
    "    print('=================================================================================')\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:10,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['summary'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_2000-AGENDA_1</td>\n",
       "      <td>제 173 회 제 1 차 정례회 제 1 차 본회의개의선포 . 금번 제 1 차 본회...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_2000-AGENDA_2</td>\n",
       "      <td>제 279 회 음성군 의회 제 1 차 정례회의회기는 2012 년 6 월 15 일부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2000-AGENDA_3</td>\n",
       "      <td>제 279 회 제 1 차 정례회 회의록 서명 의원으로 이한철 의원 , 정태완 의원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_2000-AGENDA_4</td>\n",
       "      <td>예산 결산 특별 위원회 위원은 이한철 의원 , 정태완 의원 , 남궁유 의원 , 조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_2000-AGENDA_5</td>\n",
       "      <td>주요 사업 현지 확인 특별 위원회 구성 결의안은 6 월 30 일부터 6 월 1 일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uid                                            summary\n",
       "0  id_2000-AGENDA_1   제 173 회 제 1 차 정례회 제 1 차 본회의개의선포 . 금번 제 1 차 본회...\n",
       "1  id_2000-AGENDA_2   제 279 회 음성군 의회 제 1 차 정례회의회기는 2012 년 6 월 15 일부...\n",
       "2  id_2000-AGENDA_3   제 279 회 제 1 차 정례회 회의록 서명 의원으로 이한철 의원 , 정태완 의원...\n",
       "3  id_2000-AGENDA_4   예산 결산 특별 위원회 위원은 이한철 의원 , 정태완 의원 , 남궁유 의원 , 조...\n",
       "4  id_2000-AGENDA_5   주요 사업 현지 확인 특별 위원회 구성 결의안은 6 월 30 일부터 6 월 1 일..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('dacon_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제출 API 사용법 => https://dacon.io/forum/403557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "    'dacon_baseline.csv', \n",
    "    '개인 Token', \n",
    "    '235813',\n",
    "    'BASELINE', \n",
    "    'DACON_Baseline'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eunil",
   "language": "python",
   "name": "eunil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
